/* --------------------------------------------------------------------
   Folder tags on datasets 
   -------------------------------------------------------------------- */
	ng    -> dataset has car, pedestrian, cyclists labels but no ground labels. 
	g     -> dataset has car, pedestrian, cyclists and ground labels
	mc 	 -> dataset has car, ground labels, and pedestran and cyclist labels were merged.
	vlp64 -> Velodyne VLP64 scans
	vlp32 -> Velodyne VLP32 scans
	vlp16 -> Velodyne VLP16 scans
	vX  	 -> x version of the dataset

/* -------------------------------------------------------------------- 
   Applying transformations to point clouds (PCL):
    - Convert PCL from .npy format to .txt
    - Convert PCL from .txt formta to .npy 
    - Downsample PCL from 64 scanlines to 32 and 16 scanlines
    - Merge selected classes in PCL
   -------------------------------------------------------------------- */

	// Downsample the VLP64 files  
	python scripts/convert.py \
		--inpath [./path/to/input/dataset/] \
		--outpath [./path/to/output/dataset/] \
		--conv downs
		

	// Convert the VLP64 .npy files to .txt files 
	python scripts/convert.py \
		--inpath [./path/to/input/dataset/] \
		--outpath [./path/to/output/dataset/] \
		--label [g | ng | mcg | mcng] \ // ground, no-ground, merged classes ground, merge classes no ground
		--conv txt \
	
	// Convert the VLP64 .txt files to .npy files 
	python scripts/convert.py \
		--inpath [./path/to/input/dataset/] \
		--outpath [./path/to/output/dataset/] \
		--outdir dirname \
		--label [g | ng | mcg | mcng] \
		--azimuth 512 \
		--zenith 64 \
		--conv npy \

	// Merge two classes 
	python scripts/convert.py \
		--inpath [./path/to/input/dataset/] \
		--outpath [./path/to/output/dataset/] \
		--outdir [dirname] \
		--label [g | ng | mcg | mcng] \
		--cls1 2 \  // Class to keep
		--cls2 3 \  // Class to convert into cls1
		--conv merge \
		
/* -------------------------------------------------------------------- 
   Command to annotate VLP64 .txt files
   -------------------------------------------------------------------- */
	./extractGround \
		--inpath  [./path/to/input/dataset/] \
		--outpath [./path/to/output/dataset] \
		--seg 4 \
		--lpr 20 \
		--iter 3 \
		--thseed 0.8 \
		--thdist 0.5 \
		--method [true | false] // True -> uses means to get seeds, False --> uses medians

/* -------------------------------------------------------------------- 
   Generating train / val files 
   -------------------------------------------------------------------- */
   python scritps/trainval.py \
   		--inpath [./path/to/input/datasets/ \
   		--outdir ImageSet \ // Directory to store train.txt and val.txt
   		--train 85 // percentage of training samples
   		
/* -------------------------------------------------------------------- 
   SqueezeSeg 
   -------------------------------------------------------------------- */
   
   	// KITTI configurations for SqueezeSeg 
	kitti_squeezeSeg_config       --> VLP64, classes: pedestrian, cyclist, car, unknown
	kitti_squeezeSeg_config_ext   --> VLP64, classes: pedestrian, cyclist, car, ground, unknown
	kitti_squeezeSeg_config_red   --> VLP64, classes: person (pedestrian and cyclist), car, ground, unkown

	kitti_squeezeSeg32_config     --> VLP32, classes: pedestrian, cyclist, car, unknown
	kitti_squeezeSeg32_config_ext --> VLP32, classes: pedestrian, cyclist, car, ground, unknown
	kitti_squeezeSeg32_config_red --> VLP32, classes: person (pedestrian and cyclist), car, ground, unkown

	kitti_squeezeSeg16_config     --> VLP16, classes: pedestrian, cyclist, car, unknown
	kitti_squeezeSeg16_config_ext --> VLP16, classes: pedestrian, cyclist, car, ground, unknown
	kitti_squeezeSeg16_config_red --> VLP16, classes: person (pedestrian and cyclist), car, ground, unkown
	
	// Activate environment for SqueezeSeg
	source env/bin/activate
	
	// Training SqueezeSeg
	./scripts/train.sh \
		-gpu 0 \
		-image_set [train | val] \
		-log_dir [./path/to/log/directory] \
		-net [SqueezeSeg | SqueezeSeg32 | SqueezeSeg16] \
		-data_dir [./path/to/data/directory/] \
		-res [y | n] \
		-label [g | ext | red] \
		-max_steps [num of steps]
	
	// Evaluation SqueezeSeg
	./scripts/eval.sh \
		-gpu 0 \
		-image_set [train | val] \
		-log_dir [./path/to/log/directory] \
		-net [SqueezeSeg | SqueezeSeg32 | SqueezeSeg16] \
		-data_dir [./path/to/data/directory/] \
		-res [y | n] \
		-label [g | ext | red] \
		-max_steps [num of steps] \
		-ckpt_steps [checkpoint steps]
		
	// Visualizing results
	tensorboard --logdir=./path/to/logs
	
/* -------------------------------------------------------------------- 
   Github
   -------------------------------------------------------------------- */
   git reset --hard HEAD
   git pull 

/* -------------------------------------------------------------------- 
   List of tests to do on VLP16 Downsampled data
   -------------------------------------------------------------------- */
   Firemodules completos 
	   Non-ground 
	   	-- unkown, cars, pedestrians, cyclists           		--> log16ng
	   	
	   	
	   	-- unknown, cars, human (pedestran + cyclists)  		--> 
	   Ground
	   	-- unkown, ground, cars, pedestrians, cyclists
	   	-- unknown, ground, cars, human (pedestran + cyclists)
   Firemodules reducidos 
	   Non-ground 
	   	-- unkown, cars, pedestrians, cyclists            	--> log16ngf       
	   	-- unknown, cars, human (pedestran + cyclists)   
	   Ground
	   	-- unkown, ground, cars, pedestrians, cyclists
	   	-- unknown, ground, cars, human (pedestran + cyclists)
   
   
   
